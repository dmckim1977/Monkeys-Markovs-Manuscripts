{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuous-time Markov chains (CTMC)\n",
    "- Ross: Chapters 6.1-6.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6.1 Introduction**\n",
    "\n",
    "- One example of a continuous-time Markov chain is Poisson process\n",
    "  - Let the total number of arrivals by time $t$ ($N(t)$) be the state of the process at time $t$, then the Poisson process is a continuous time Markov chain having states $0, 1, 2, \\dots $ that always proceeds from state $n$ to state $n + 1$, where $n \\geq 0$\n",
    "  - Process is known as a ***pure birth process*** since when a transition occurs the state of the system is always increased by one\n",
    "\n",
    "- An exponential model that can go (in one transition) only from state $n$ to either state $n − 1$ or state $n + 1$ is called a ***birth and death model***\n",
    "  - transitions from state $n$ to state $n+1$ are designated as births, and those from $n$ to $n−1$ as deaths\n",
    "  - biological systems, waiting line systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6.2 Continuous-Time Markov Chains**\n",
    "\n",
    "Suppose we have a continuous-time stochastic process $\\{X(t), t \\geq 0\\}$ taking on values in the set of nonnegative integers. We can say that the process $\\{X(t), t \\geq 0\\}$ is a continuous-time Markov chain if for all s,t ≥ 0 and nonnegative integers $i,j , x(u), 0 \\leq u < s$\n",
    "\n",
    "$$\n",
    "P\\{X(t + s) = j \\mid X(s) = i, X(u) = x(u), 0 \\leq u < s\\} = P\\{X(t + s) = j \\mid X(s) = i\\}\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "A continuous-time Markov chain is a stochastic process having the Markovian property that the conditional distribution of the future $X(t + s)$ given the present $X(s)$ and the past $X(u), 0 \\leq u < s$, depends only on the present and is independent of the past. If $P\\{X(t + s) = j \\mid X(s) = i\\}$ is independent of $s$, then the continuous-time Markov chain is said to have stationary or homogeneous transition probabilities. \n",
    "\n",
    "<br>\n",
    "\n",
    "Suppose that a continuous-time Markov chain enters state $i$ at some time, say, time 0, and suppose that the process does not leave state $i$ (that is, a transition does not occur) during the next ten minutes. What is the probability that the process will not leave state $i$ during the following five minutes?\n",
    "\n",
    "- process is in state i at time 10\n",
    "- by the Markovian property, that the probability that it remains in that state during the interval $[10,15]$ is just the (unconditional) probability that it stays in state $i$ for at least five minutes\n",
    "- $T_i$ denotes the amount of time that the process stays in state i before making a transition into a different state\n",
    "\n",
    "$$\n",
    "P\\{T_i > 15 \\mid T_i > 10\\} = P\\{T_i > 5\\}\n",
    "$$\n",
    "\n",
    "Generally,\n",
    "\n",
    "$$\n",
    "P\\{T_i > s + t \\mid T_i > s\\} = P\\{T_i > t\\}, \\quad \\text{for all } s,t \\geq 0\n",
    "$$\n",
    "\n",
    "- the random variable $T_i$ is memoryless and must thus be exponentially distributed\n",
    "\n",
    "<br>\n",
    "\n",
    "Another way of defining a continuous-time Markov chain: It is a stochastic process having the properties that each time it enters state $i$\n",
    "> (i) the amount of time it spends in that state before making a transition into a different state is exponentially distributed with mean, say $1/v_i$\n",
    "> (ii) when the process leaves state i, it next enters state j with some probability, say, $P_{ij}$, must satisfy\n",
    "  >> $P_{ii} = 0$, all $i$ \\\n",
    "  >> $\\sum P_{ij} = 1$, all $i$\n",
    "\n",
    "- a continuous-time Markov chain is a stochastic process that moves from state to state in accordance with a (discrete-time) Markov chain, but is such that the amount of time it spends in each state, before proceeding to the next state, is exponentially distributed\n",
    "- the amount of time the process spends in state i, and the next state visited, must be independent random variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example 6.1 (A Shoe Shine Shop)**: Consider a shoe shine establishment consisting of two chairs—chair 1 and chair 2. A customer upon arrival goes initially to chair 1 where his shoes are cleaned and polish is applied. After this is done the customer moves on to chair 2 where the polish is buffed. The service times at the two chairs are assumed to be independent random variables that are exponentially distributed with respective rates $μ_1$ and $μ_2$. Suppose that potential customers arrive in accordance with a Poisson process having rate $λ$, and that a potential customer will enter the system only if both chairs are empty.\n",
    "\n",
    "- states:\n",
    "  - state 0: system is empty\n",
    "  - state 1: a customer is in chair 1 \n",
    "  - state 2: a customer is in chair 2\n",
    "\n",
    "- transition rates\n",
    "  - $v_0$: This is the rate of transition from state 0 to state 1. Since a customer will only enter the system if both chairs are empty, and given that arrivals are a Poisson process with rate λ, the rate of entering state 1 from state 0 is exactly $λ$. \n",
    "  - $v_1$: This is the rate of transition from state 1 to state 2. When a customer is in chair 1, they will move to chair 2 as soon as the service at chair 1 is completed. Since the service times are exponentially distributed with rate $μ_1$, the rate of moving from chair 1 to chair 2 is $μ_1$.\n",
    "  - $v_2$: This is the rate of transition from state 2 back to state 0. After finishing the service at chair 2, the customer leaves the system. Given that service times at chair 2 are also exponentially distributed with rate $μ_2$, the rate of exiting from chair 2 (and thus returning to the empty state) is $μ_2$.\n",
    "\n",
    "- transition probabilities\n",
    "  - $P_{01}$: The probability of moving from state 0 to state 1. As per the system's description, a customer enters the system (going to chair 1) if and only if both chairs are empty. Since this is the only transition possible from state 0, $P_{01} = 1$.\n",
    "  - $P_{12}$: The probability of moving from state 1 to state 2. Once a customer is in chair 1, the only next possible state under normal operation is that they move to chair 2 after their service at chair 1 is complete, hence $P_{12} = 1$.\n",
    "  - $P_{20}$: The probability of moving from state 2 to state 0. After finishing the service at chair 2, the customer leaves the system, and the system returns to being empty. As this is the only transition possible from state 2, $P_{20} = 1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6.3 Birth and Death Processes**\n",
    "\n",
    "Consider a system whose state at any time is represented by the number of people in the system at that time. Suppose that whenever there are $n$ people in the system, then \n",
    "- (i) new arrivals enter the system at an exponential rate $λ_n$, and \n",
    "- (ii) people leave the system at an exponential rate $μ_n$. That is, whenever there are $n$ persons in the system, then the time until the next arrival is exponentially distributed with mean $1/λn$ and is independent of the time until the next departure, which is itself exponentially distributed with mean $1/μ_n$\n",
    "\n",
    "Such a system is called a birth and death process. The parameters \n",
    "\n",
    "The **arrival (or birth)** rate:\n",
    "$$\n",
    "\\{λ_n\\}_{n=0}^\\infty\n",
    "$$\n",
    "\n",
    "The **departure (or death)** rate:\n",
    "$$\n",
    "\\{\\mu_n\\}_{n=1}^\\infty\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "A birth and death process is a continuous-time Markov chain with states $\\{0, 1, \\ldots \\}$ for which transitions from state $n$ may go only to either state $n - 1$ or state $n + 1$. The relationships between the birth and death rates and the state transition rates and probabilities are:\n",
    "\n",
    "- $v_0 = \\lambda_0$,\n",
    "- $v_i = \\lambda_i + \\mu_i$ for $i > 0$.\n",
    "\n",
    "The transition probabilities are given by:\n",
    "- $P_{01} = 1$,\n",
    "- $P_{i,i+1} = \\frac{\\lambda_i}{\\lambda_i + \\mu_i}$ for $i > 0$,\n",
    "- $P_{i,i-1} = \\frac{\\mu_i}{\\lambda_i + \\mu_i}$ for $i > 0$. \n",
    "\n",
    "This follows because if there are $i$ in the system, then the next state will be $i + 1$ if a birth occurs before a death. The probability that an exponential random variable with rate $\\lambda_i$ will occur earlier than an (independent) exponential with rate $\\mu_i$ is $\\frac{\\lambda_i}{\\lambda_i + \\mu_i}$. Moreover, the time until either a birth or a death occurs is exponentially distributed with rate $\\lambda_i + \\mu_i$ (and so, $v_i = \\lambda_i + \\mu_i$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example 6.2 (The Poisson Process)**: Consider a birth and death process for which\n",
    "- $μ_n = 0$, for all $n ≥ 0$\n",
    "- $λ_n = λ$, for all $n ≥ 0$\n",
    "\n",
    "This is a process in which departures never occur, and the time between successive arrivals is exponential with mean $1/λ$. Hence, this is just the Poisson process\n",
    "\n",
    "A birth and death process for which $μ_n = 0$ for all $n$ is called a pure birth process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example 6.3 (A Birth Process with Linear Birth Rate):** Consider a population whose members can give birth to new members but cannot die. If each member acts independently of the others and takes an exponentially distributed amount of time, with mean $1/λ$, to give birth, then if $X(t)$ is the population size at time $t$, then $\\{X(t), t ≥ 0\\}$ is a pure birth process with $λ_n = nλ,n ≥ 0$. This follows since if the population consists of $n$ persons and each gives birth at an exponential rate $λ$, then the total rate at which births occur is $nλ$. This pure birth process is known as a ***Yule process*** after G. Yule, who used it in his mathematical theory of evolution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example 6.4 (A Linear Growth Model with Immigration):** A model in which\n",
    "\n",
    "$$\n",
    "μ_n = nμ, \\quad n ≥ 1\n",
    "$$\n",
    "$$\n",
    "λ_n = nλ + θ, \\quad n ≥ 0\n",
    "$$\n",
    "\n",
    "is called a linear growth process with immigration. Such processes occur naturally in the study of biological reproduction and population growth. Each individual in the population is assumed to give birth at an exponential rate $λ$; in addition, there is an exponential rate of increase $θ$ of the population due to an external source such as immigration. Hence, the total birth rate where there are $n$ persons in the system is $nλ + θ$. Deaths are assumed to occur at an exponential rate $μ$ for each member of the population, so $μn = nμ$\n",
    "\n",
    "- $X(t)$ denotes the population size at time $t$\n",
    "- $X(0) = i$, $M(t) = E[X(t)]$\n",
    "  - will determine M(t) by deriving and then solving a differential equation that it satisfies: \n",
    "\n",
    "Conditioning on X(t),\n",
    "$$\n",
    "M(t + h) = E[X(t + h)] = E[E[X(t + h)|X(t)]]\n",
    "$$\n",
    "\n",
    "Given the size of the population at time $t$ then, ignoring events whose probability is $o(h)$, the population at time $t + h$ will either increase in size by 1 if a birth or an immigration occurs in $(t,t + h)$, or decrease by 1 if a death occurs in this interval, or remain the same if neither of these two possibilities occurs:\n",
    "\n",
    "$$\n",
    "X(t + h) = \n",
    "\\begin{cases} \n",
    "X(t) + 1, & \\text{with probability } [\\theta + X(t)\\lambda]h + o(h) \\\\\n",
    "X(t) - 1, & \\text{with probability } X(t)\\mu h + o(h) \\\\\n",
    "X(t), & \\text{with probability } 1 - [\\theta + X(t)\\lambda + X(t)\\mu]h + o(h)\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\implies\n",
    "$$\n",
    "\n",
    "$$\n",
    "E[X(t + h)|X(t)] = X(t) + [θ + X(t)λ − X(t)μ]h + o(h) \\implies M(t + h) = M(t) + (λ − μ)M(t)h + θh + o(h)\n",
    "$$\n",
    "\n",
    "Take limit as $\\lim_{h\\rightarrow 0} M(t + h)$ to get differential equation\n",
    "$$\n",
    "M'(t) = (λ − μ)M(t) + θ\n",
    "$$\n",
    "$$\n",
    "h(t) = (λ − μ)M(t) + θ \\implies h'(t) = (λ − μ)M'(t)\n",
    "$$\n",
    "\n",
    "The differential equation can be rewritten as:\n",
    "$$\n",
    "\\frac{d}{dt} h(t) = (\\lambda - \\mu) h(t)\n",
    "$$\n",
    "or equivalently:\n",
    "$$\n",
    "\\frac{d}{dt} h(t) \\Big/ h(t) = \\lambda - \\mu\n",
    "$$\n",
    "Integration yields:\n",
    "$$\n",
    "\\log[h(t)] = (\\lambda - \\mu)t + c\n",
    "$$\n",
    "or\n",
    "$$\n",
    "h(t) = Ke^{(\\lambda-\\mu)t}\n",
    "$$\n",
    "Putting this back in terms of $M(t)$ gives:\n",
    "$$\n",
    "\\theta + (\\lambda - \\mu)M(t) = Ke^{(\\lambda-\\mu)t}\n",
    "$$\n",
    "To determine the value of the constant $K$, we use the fact that $M(0) = i$ and evaluate the preceding at $t = 0$. This gives:\n",
    "$$\n",
    "\\theta + (\\lambda - \\mu)i = K\n",
    "$$\n",
    "Substituting this back in the preceding equation for $M(t)$ yields the following solution for $M(t)$:\n",
    "$$\n",
    "M(t) = \\frac{\\theta}{\\lambda - \\mu} [e^{(\\lambda-\\mu)t} - 1] + ie^{(\\lambda-\\mu)t}\n",
    "$$\n",
    "Note that we have implicitly assumed that $\\lambda \\neq \\mu$. If $\\lambda = \\mu$, then differential equation reduces to:\n",
    "$$\n",
    "\\dot{M}(t) = \\theta \\quad (6.2)\n",
    "$$\n",
    "Integrating (6.2) and using that $M(0) = i$ gives the solution:\n",
    "$$\n",
    "M(t) = \\theta t + i\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider now a general birth and death process with birth rates $\\{λ_n\\}$ and death rates $\\{μ_n\\}$, where $μ_0 = 0$, and let $T_i$ denote the time, starting from state $i$, it takes for the process to enter state $i + 1,i ≥ 0$. We will recursively compute $E[T_i],i ≥ 0$, by starting with $i = 0$. Since $T_0$ is exponential with rate $λ_0$, we have $E[T_0] = \\frac{1}{\\lambda_0}$\n",
    "\n",
    "For $i > 0$, we condition on whether the first transition takes the process into state $i - 1$ or $i + 1$. That is, let $I_i$ be defined as:\n",
    "$$\n",
    "I_i = \n",
    "\\begin{cases} \n",
    "1, & \\text{if the first transition from } i \\text{ is to } i + 1 \\\\\n",
    "0, & \\text{if the first transition from } i \\text{ is to } i - 1\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "$$\n",
    "E[T_i \\mid I_i = 1] = \\frac{1}{\\lambda_i + \\mu_i},\n",
    "$$\n",
    "$$\n",
    "E[T_i \\mid I_i = 0] = \\frac{1}{\\lambda_i + \\mu_i} + E[T_{i-1}] + E[T_i]\n",
    "$$\n",
    "\n",
    "independent of whether the first transition is from a birth or death, the time until it occurs is exponential with rate $λi + μi$;\n",
    "\n",
    "if this first transition is a birth, then the population size is at $i + 1$, so no additional time is needed; whereas if it is death, then the population size becomes $i − 1$ and the additional time needed to reach $i + 1$ is equal to the time it takes to return to state $i$ (this has mean $E[T_i−1]$) plus the additional time it then takes to reach $i + 1$ (this has mean $E[T_i]$):\n",
    "\n",
    "$$\n",
    "E[T_i] = \\frac{1}{\\lambda_i + \\mu_i} + \\frac{\\mu_i}{\\lambda_i + \\mu_i} (E[T_{i-1}] + E[T_i]) = \\frac{1}{\\lambda_i} + \\frac{\\mu_i}{\\lambda_i} E[T_{i-1}], \\quad i \\geq 1\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose now that we wanted to determine the expected time to go from state $i$ to state $j$ where $i < j$. This can be accomplished using the preceding by noting that this quantity will equal $E[T_i] + E[T_i+1]+ \\dots + E[T_j−1]$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img](images/ross_example6.7.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also compute the variance of the time to go from state 0 to state $i + 1$ by utilizing the conditional variance formula.\n",
    "$$\n",
    "E[T_i \\mid I_i] = \\frac{1}{\\lambda_i + \\mu_i} + (1 - I_i)(E[T_{i-1}] + E[T_i])\n",
    "$$\n",
    "Thus,\n",
    "$$\n",
    "\\text{Var}(E[T_i \\mid I_i]) = (E[T_{i-1}] + E[T_i])^2 \\text{Var}(I_i) = (E[T_{i-1}] + E[T_i])^2 \\frac{\\mu_i \\lambda_i}{(\\mu_i + \\lambda_i)^2} \n",
    "$$\n",
    "where $\\text{Var}(I_i)$ is as shown since $I_i$ is a Bernoulli random variable with parameter $p = \\frac{\\lambda_i}{\\lambda_i + \\mu_i}$. Also, note that if we let $X_i$ denote the time until the transition from state $i$ occurs, then\n",
    "$$\n",
    "\\text{Var}(T_i \\mid I_i = 1) = \\text{Var}(X_i \\mid I_i = 1) = \\text{Var}(X_i) = \\frac{1}{(\\lambda_i + \\mu_i)^2} \n",
    "$$\n",
    "where the preceding uses the fact that the time until transition is independent of the next state visited. Also,\n",
    "$$\n",
    "\\text{Var}(T_i \\mid I_i = 0) = \\text{Var}(X_i + \\text{time to get back to } i + \\text{time to then reach } i + 1) = \\text{Var}(X_i) + \\text{Var}(T_{i-1}) + \\text{Var}(T_i) \n",
    "$$\n",
    "where the foregoing uses the fact that the three random variables are independent. \n",
    "$$\n",
    "\\text{Var}(T_i \\mid I_i) = \\text{Var}(X_i) + (1 - I_i)[\\text{Var}(T_{i-1}) + \\text{Var}(T_i)]\n",
    "$$\n",
    "so\n",
    "$$\n",
    "E[\\text{Var}(T_i \\mid I_i)] = \\frac{1}{(\\mu_i + \\lambda_i)^2} + \\frac{\\mu_i}{\\mu_i + \\lambda_i} [\\text{Var}(T_{i-1}) + \\text{Var}(T_i)] \\quad (6.7)\n",
    "$$\n",
    "Hence, using the conditional variance formula:\n",
    "$$\n",
    "\\text{Var}(T_i) = \\frac{1}{(\\mu_i + \\lambda_i)^2} + \\frac{\\mu_i}{\\mu_i + \\lambda_i} [\\text{Var}(T_{i-1}) + \\text{Var}(T_i)] + \\frac{\\mu_i \\lambda_i}{(\\mu_i + \\lambda_i)^2} (E[T_{i-1}] + E[T_i])^2\n",
    "$$\n",
    "or, equivalently,\n",
    "$$\n",
    "\\text{Var}(T_i) = \\frac{1}{\\lambda_i(\\lambda_i + \\mu_i)} + \\frac{\\mu_i}{\\lambda_i} \\text{Var}(T_{i-1}) + \\frac{\\mu_i}{\\mu_i + \\lambda_i} (E[T_{i-1}] + E[T_i])^2\n",
    "$$\n",
    "Starting with $\\text{Var}(T_0) = \\frac{1}{\\lambda_0^2}$ and using the former recursion to obtain the expectations, we can recursively compute $\\text{Var}(T_i)$. In addition, if we want the variance of the time to reach state $j$, starting from state $k$, $k < j$, then this can be expressed as the time to go from $k$ to $k +1$ plus the additional time to go from $k +1$ to $k +2$, and so on. Since, by the Markovian property, these successive random variables are independent, it follows that\n",
    "$$\n",
    "\\text{Var}(\\text{time to go from } k \\text{ to } j) = \\sum_{i=k}^{j-1} \\text{Var}(T_i)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6.4 The Transition Probability Function $P_{ij}(t)$**\n",
    "\n",
    "Let\n",
    "$$\n",
    "P_{ij} (t) = P\\{X(t + s) = j \\mid X(s) = i\\}\n",
    "$$\n",
    "denote the probability that a process presently in state $i$ will be in state $j$ a time $t$ later. These quantities are often called the transition probabilities of the continuous-time Markov chain\n",
    "\n",
    "<br>\n",
    "\n",
    "We have for a pure birth process that:\n",
    "$$\n",
    "P\\{X(t) < j \\mid X(0) = i\\} = P \\left\\{ \\sum_{k=i}^{j-1} X_k > t \\right\\}\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $X_i$ is the time it spends in state $i$ before moving to state $i + 1$; $X_{i+1}$ is the time it spends in state $i + 1$ before moving to state $i + 2$, and so on ...\n",
    "- $ \\sum_{k=i}^{j-1} X_k $ is the time it takes until the process enters state $j$\n",
    "- if the process has not yet entered state $j$ by time $t$, then its state at time $t$ is smaller than $j$, and vice versa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that $X_i, \\ldots, X_{j-1}$ are independent exponential random variables with respective rates $\\lambda_i, \\ldots, \\lambda_{j-1}$, we obtain from the preceding, which gives the tail distribution function of $\\sum_{k=i}^{j-1} X_k$, that:\n",
    "$$\n",
    "P\\{X(t) < j \\mid X(0) = i\\} = \\prod_{k=i}^{j-1} e^{-\\lambda_k t} \\prod_{\\substack{r=k, r=i}}^{j-1} \\frac{\\lambda_r}{\\lambda_r - \\lambda_k}\n",
    "$$\n",
    "Replacing $j$ by $j + 1$ in the preceding gives:\n",
    "$$\n",
    "P\\{X(t) < j + 1 \\mid X(0) = i\\} = \\prod_{k=i}^{j} e^{-\\lambda_k t} \\prod_{\\substack{r=k, r=i}}^{j} \\frac{\\lambda_r}{\\lambda_r - \\lambda_k}\n",
    "$$\n",
    "Since:\n",
    "$$\n",
    "P\\{X(t) = j \\mid X(0) = i\\} = P\\{X(t) < j + 1 \\mid X(0) = i\\} - P\\{X(t) < j \\mid X(0) = i\\}\n",
    "$$\n",
    "and since $P_{ii}(t) = P\\{X_i > t\\} = e^{-\\lambda_i t}$, we have shown the following."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Proposition 6.1.** For a pure birth process having $\\lambda_i \\neq \\lambda_j$ when $i \\neq j$:\n",
    "$$\n",
    "P_{ij}(t) = \\left(\\sum_{k=i}^{j} e^{-\\lambda_k t} \\prod_{\\substack{r \\ne k, r=i}}^{j} \\frac{\\lambda_r}{\\lambda_r - \\lambda_k}\\right) - \\left(\\sum_{k=i}^{j-1} e^{-\\lambda_k t} \\prod_{\\substack{r \\ne k, r=i}}^{j-1} \\frac{\\lambda_r}{\\lambda_r - \\lambda_k}\\right), \\quad i<j\n",
    "$$\n",
    "$$\n",
    "P_{ii}(t) = e^{-\\lambda_i t}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example 6.8:**. Consider the Yule process, which is a pure birth process in which each individual in the population independently gives birth at rate $λ$, and so $λn = nλ, n ≥ 1$.\n",
    "\n",
    "From prop 6.1:\n",
    "\n",
    "![Img](images/ross_example6.8.jpg)\n",
    "\n",
    "- the population size at time $t$ has a geometric distribution with mean $e^{λt}$\n",
    "- population size at time $t$ has a negative binomial distribution with parameters $i$ and $e^{−λt}$\n",
    "  - If the population starts with $i$ individuals, then we can regard each of these individuals as starting her own independent Yule process $\\implies$ the population at time $t$ is sum of $i$ independent and identically distributed geometric random variables with parameter $e^{−λt}$\n",
    "  - the conditional distribution of $X(t)$, given that $X(0) = i$, is the same as the distribution of the number of times that a coin that lands heads on each flip with probability $e^{−λt}$ must be flipped to amass a total of $i$ heads\n",
    "\n",
    "$$\n",
    "P_{ij}(t) = \\binom{j-1}{i-1} e^{-i \\lambda t} (1 - e^{-\\lambda t})^{j-i}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example 6.9:** An urn initially contains one type 1 and one type 2 ball. At each stage, a ball is chosen from the urn, with the chosen ball being equally likely to be any of the balls in the urn. If a type i ball is chosen, then an experiment that is successful with probability $p_i$ is performed; if it is successful then the ball chosen along with a new type $i$ ball are put in the urn, and if it is unsuccessful then only the ball chosen is put in the urn, $i = 1, 2$. We then move to the next stage. We are interested in determining the mean numbers of type 1 and type 2 balls in the urn after $n$ stages\n",
    "\n",
    "![Img](images/ross_example6.9.jpg)\n",
    "![Img](images/ross_example6.9_2.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For any pair of states $i$ and $j$, let $q_{ij} = v_{i}P_{ij}$. Since $v_i$ is the rate at which the process makes a transition when in state $i$ and $P_{ij}$ is the probability that this transition is into state $j$, it follows that $q_{ij}$ is the rate, when in state $i$, at which the process makes a transition into state $j$.\n",
    "\n",
    "The quantities qij are called the ***instantaneous transition rates***. Since\n",
    "\n",
    "$$\n",
    "v_i = \\sum_j v_i P_{ij} = \\sum_j q_{ij}\n",
    "$$\n",
    "and\n",
    "$$\n",
    "P_{ij} = \\frac{q_{ij}}{v_i} = \\frac{q_{ij}}{\\sum_j q_{ij}}\n",
    "$$\n",
    "\n",
    "![Img](images/ross_example6_lemmas.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From applying Lemma 6.2, \n",
    "\n",
    "**Theorem 6.1 (Kolmogorov’s Backward Equations):** For all states $i,j,$ and times $t ≥ 0$,\n",
    "$$\n",
    "{P'}_{ij}(t) = \\sum_{k \\neq i} q_{ik} P_{kj}(t) - v_i P_{ij}(t)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another set of differential equations, different from the backward equations, may also be derived. This set of equations, known as Kolmogorov’s forward equations is derived as follows. From the Chapman–Kolmogorov equations (Lemma 6.3). This assumes that we can interchange limit with summation. Unfortunately, we cannot always justify the interchange of limit and summation and thus the preceding is not always valid. However, they do hold in most models, including all birth and death processes and all finite state models. We thus have the following: \n",
    "\n",
    "**Theorem 6.2 (Kolmogorov’s Forward Equations):** Under suitable regularity conditions,\n",
    "$$\n",
    "{P'}_{ij}(t) = \\sum_{k \\neq i} q_{kj} P_{ik}(t) - v_j P_{ij}(t)\n",
    "$$\n",
    "\n",
    "- Forward equations for the pure birth process $(P_{ij} = 0)$:\n",
    "$$\n",
    "P'_{ii}(t) = −λ_iP_{ii}(t)\n",
    "$$\n",
    "$$\n",
    "P'_{ij}(t) = \\lambda_{j-1} P_{i,j-1}(t) - \\lambda_j P_{ij}(t) , \\quad j \\geq i + 1\n",
    "$$\n",
    "\n",
    "**Proposition 6.4.** For a pure birth process:\n",
    "- The probability of remaining in state $i$ until time $t$ is given by:\n",
    "$$\n",
    "P_{ii}(t) = e^{-\\lambda_i t}, \\quad i \\geq 0\n",
    "$$\n",
    "- The probability of transitioning from state $i$ to state $j$ (where $j \\geq i + 1)$ is given by:\n",
    "$$\n",
    "P_{ij}(t) = \\lambda_{j-1} e^{-\\lambda_j t} \\int_0^t e^{\\lambda_j s} P_{i, j-1}(s) \\, ds\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example 6.11 (A Continuous-Time Markov Chain Consisting of Two States):** Consider a machine that works for an exponential amount of time having mean $1/λ$ before breaking down; and suppose that it takes an exponential amount of time having mean $1/μ$ to repair the machine. If the machine is in working condition at time 0, then what is the probability that it will be working at time $t = 10$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example 6.12 (Forward Equations for Birth and Death Process):**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6.5 Limiting Probabilities**\n",
    "\n",
    "The probability that a continuous-time Markov chain will be in state j at time t often converges to a limiting value that is independent of the initial state. That is, if we call this value Pj , then \n",
    "\n",
    "$$\n",
    "P_j = \\lim_{t \\rightarrow \\infty} P_{ij}(t)\n",
    "$$\n",
    "\n",
    "where we are assuming that the limit exists and is independent of the initial state $i$.\n",
    "\n",
    "$$\n",
    "\\sum_{j} P_j = 1\n",
    "$$\n",
    "can be used to solve for the limiting probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The limiting probabilities for a birth and death process:\n",
    "\n",
    "![Img](images/ross_example_limitingprobs.jpg)\n",
    "\n",
    "- condition is satisfied when $λ < μ$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Img](images/ross_example_statprobs.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
